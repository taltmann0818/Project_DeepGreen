{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:56:41.461372Z",
     "start_time": "2025-04-26T15:56:38.630334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom libraries\n",
    "from Components.TrainModel import DataModule, TEMPUS, torchscript_predict\n",
    "from Components.TickerData import TickerData, upload_data_sql, fetch_sql_data\n",
    "from Components.BackTesting import BackTesting\n",
    "from Components.MarketRegimes import MarketRegimes\n",
    "\n",
    "# Torch ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ],
   "id": "d79796ccc1eff616",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:56:41.572758Z",
     "start_time": "2025-04-26T15:56:41.569838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TODO: Include alpha in the backtesting results (based on index comparison) from quantstats package\n",
    "#TODO: Streamlit Page for future prediction\n",
    "\n",
    "# -- Model Features/Data --\n",
    "#TODO: Use following news sentiment features: [\"positive_count\",\"neutral_count\",\"negative_count\",\"total_count\",\"pos_sent_ratio\",\"neg_sent_ratio\",\"net_sentiment\"]\n",
    "#TODO: Parse financials data from Pologon.IO\n",
    "#TODO: Include index volitility in the training data\n",
    "\n",
    "# -- Model Training --"
   ],
   "id": "550308f7847289da",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:56:42.940110Z",
     "start_time": "2025-04-26T15:56:41.581293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the Wikipedia page title and section header\n",
    "sample_size = 50\n",
    "\n",
    "nasdaq_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")[4]\n",
    "nasdaq_tickers = nasdaq_tickers.iloc[:, [1]].to_numpy().flatten()\n",
    "nasdaq_tickers = np.random.choice(nasdaq_tickers, size=sample_size, replace=False)\n",
    "rusell_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Russell_1000_Index\")[3]\n",
    "rusell_tickers = rusell_tickers.iloc[:, [1]].to_numpy().flatten()\n",
    "rusell_tickers = np.random.choice(rusell_tickers, size=sample_size, replace=False)\n",
    "SnP500_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0]\n",
    "SnP500_tickers = SnP500_tickers.iloc[:, [0]].to_numpy().flatten()\n",
    "SnP500_tickers = np.random.choice(SnP500_tickers, size=sample_size, replace=False)\n",
    "SnP600_tickers = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_600_companies\")[0]\n",
    "SnP600_tickers = SnP600_tickers.iloc[:, [0]].to_numpy().flatten()\n",
    "SnP600_tickers = np.random.choice(SnP600_tickers, size=sample_size, replace=False)\n",
    "\n",
    "tickers = np.concatenate((nasdaq_tickers,rusell_tickers,SnP500_tickers,SnP600_tickers))\n",
    "tickers = np.unique(tickers)"
   ],
   "id": "a32cddf28161a0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:56:55.939285Z",
     "start_time": "2025-04-26T15:56:42.949632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tickers = ['IONQ']\n",
    "indicators = ['ema_20', 'ema_50', 'ema_200', 'stoch_rsi14','stoch_rsi28', 'macd', 'b_percent', 'keltner_lower', 'keltner_upper','State','bearish','bullish','hold','mixed','negative','neutral','positive','z_score','atr','price_momentum','volume_momentum','Close']\n",
    "#indicators = ['bearish','bullish','hold','mixed','negative','neutral','positive']\n",
    "training_data, raw_stock_data = TickerData(tickers,years=5,prediction_window=5,indicator_list=indicators).process_all()\n",
    "training_data"
   ],
   "id": "b2bc148132dcffdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          Ticker  shifted_prices  volume_momentum  positive  \\\n",
       "date                                                                          \n",
       "2020-10-26 00:00:00-04:00   AAPL          115.98         0.869506       0.0   \n",
       "2020-10-27 00:00:00-04:00   AAPL          117.51         0.728783       0.0   \n",
       "2020-10-28 00:00:00-04:00   AAPL          116.87         1.119627       0.0   \n",
       "2020-10-29 00:00:00-04:00   AAPL          115.75         1.135187       0.0   \n",
       "2020-10-30 00:00:00-04:00   AAPL          115.04         1.440504       0.0   \n",
       "...                          ...             ...              ...       ...   \n",
       "2025-04-21 00:00:00-04:00     ZS          198.08         0.591352       0.0   \n",
       "2025-04-22 00:00:00-04:00     ZS          199.44         0.544220       0.0   \n",
       "2025-04-23 00:00:00-04:00     ZS          204.64         0.813967       0.0   \n",
       "2025-04-24 00:00:00-04:00     ZS          202.87         0.978322       0.0   \n",
       "2025-04-25 00:00:00-04:00     ZS          201.09         1.045574       0.0   \n",
       "\n",
       "                              ema_200   z_score  negative  mixed  b_percent  \\\n",
       "date                                                                          \n",
       "2020-10-26 00:00:00-04:00   95.616239 -0.396171       0.0    0.0   0.339266   \n",
       "2020-10-27 00:00:00-04:00   95.825032 -0.144715       0.0    0.0   0.458687   \n",
       "2020-10-28 00:00:00-04:00   95.978017 -1.022046       0.0    0.0   0.053102   \n",
       "2020-10-29 00:00:00-04:00   96.170475 -0.339153       0.0    0.0   0.385726   \n",
       "2020-10-30 00:00:00-04:00   96.296739 -1.350059       0.0    0.0  -0.042613   \n",
       "...                               ...       ...       ...    ...        ...   \n",
       "2025-04-21 00:00:00-04:00  193.829786 -0.767500       0.0    0.0   0.379954   \n",
       "2025-04-22 00:00:00-04:00  193.856554 -0.447814       0.0    0.0   0.456718   \n",
       "2025-04-23 00:00:00-04:00  193.923554  0.012009       0.0    0.0   0.572352   \n",
       "2025-04-24 00:00:00-04:00  194.084911  1.043954       0.0    0.0   0.812322   \n",
       "2025-04-25 00:00:00-04:00  194.298793  1.601637       0.0    0.0   0.920596   \n",
       "\n",
       "                           State  ...  keltner_upper  neutral  stoch_rsi28  \\\n",
       "date                              ...                                        \n",
       "2020-10-26 00:00:00-04:00      1  ...     123.514378      0.0     0.827471   \n",
       "2020-10-27 00:00:00-04:00      1  ...     122.916686      0.0     1.000000   \n",
       "2020-10-28 00:00:00-04:00      1  ...     122.588469      0.0     0.864079   \n",
       "2020-10-29 00:00:00-04:00      1  ...     122.853416      0.0     0.907038   \n",
       "2020-10-30 00:00:00-04:00      1  ...     122.480291      0.0     0.338754   \n",
       "...                          ...  ...            ...      ...          ...   \n",
       "2025-04-21 00:00:00-04:00      0  ...     220.197013      0.0     0.448228   \n",
       "2025-04-22 00:00:00-04:00      0  ...     216.628951      0.0     0.598410   \n",
       "2025-04-23 00:00:00-04:00      0  ...     215.539892      0.0     1.000000   \n",
       "2025-04-24 00:00:00-04:00      0  ...     213.635586      0.0     1.000000   \n",
       "2025-04-25 00:00:00-04:00      0  ...     214.828624      0.0     1.000000   \n",
       "\n",
       "                               ema_50  bullish      ema_20        atr   Close  \\\n",
       "date                                                                            \n",
       "2020-10-26 00:00:00-04:00  114.097424      0.0  116.575836   3.512993  115.05   \n",
       "2020-10-27 00:00:00-04:00  114.195564      0.0  116.578138   3.538000  116.60   \n",
       "2020-10-28 00:00:00-04:00  114.078091      0.0  116.065934   3.801579  111.20   \n",
       "2020-10-29 00:00:00-04:00  114.126793      0.0  115.994893   4.062293  115.32   \n",
       "2020-10-30 00:00:00-04:00  113.920253      0.0  115.315379   4.018721  108.86   \n",
       "...                               ...      ...         ...        ...     ...   \n",
       "2025-04-21 00:00:00-04:00  198.700239      0.0  198.048613  12.137150  193.70   \n",
       "2025-04-22 00:00:00-04:00  198.614740      0.0  197.903031  12.068543  196.52   \n",
       "2025-04-23 00:00:00-04:00  198.692201      0.0  198.158932  12.107829  200.59   \n",
       "2025-04-24 00:00:00-04:00  199.141134      0.0  199.299986  11.635329  210.14   \n",
       "2025-04-25 00:00:00-04:00  199.785796      0.0  200.850464  10.807829  215.58   \n",
       "\n",
       "                           bearish  stoch_rsi14  \n",
       "date                                             \n",
       "2020-10-26 00:00:00-04:00      0.0     0.303987  \n",
       "2020-10-27 00:00:00-04:00      0.0     0.270809  \n",
       "2020-10-28 00:00:00-04:00      0.0     0.000000  \n",
       "2020-10-29 00:00:00-04:00      0.0     0.150891  \n",
       "2020-10-30 00:00:00-04:00      0.0     0.000000  \n",
       "...                            ...          ...  \n",
       "2025-04-21 00:00:00-04:00      0.0     0.475560  \n",
       "2025-04-22 00:00:00-04:00      0.0     0.478083  \n",
       "2025-04-23 00:00:00-04:00      0.0     0.859641  \n",
       "2025-04-24 00:00:00-04:00      0.0     1.000000  \n",
       "2025-04-25 00:00:00-04:00      0.0     1.000000  \n",
       "\n",
       "[204456 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>shifted_prices</th>\n",
       "      <th>volume_momentum</th>\n",
       "      <th>positive</th>\n",
       "      <th>ema_200</th>\n",
       "      <th>z_score</th>\n",
       "      <th>negative</th>\n",
       "      <th>mixed</th>\n",
       "      <th>b_percent</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>keltner_upper</th>\n",
       "      <th>neutral</th>\n",
       "      <th>stoch_rsi28</th>\n",
       "      <th>ema_50</th>\n",
       "      <th>bullish</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>atr</th>\n",
       "      <th>Close</th>\n",
       "      <th>bearish</th>\n",
       "      <th>stoch_rsi14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-26 00:00:00-04:00</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>115.98</td>\n",
       "      <td>0.869506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.616239</td>\n",
       "      <td>-0.396171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339266</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>123.514378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827471</td>\n",
       "      <td>114.097424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.575836</td>\n",
       "      <td>3.512993</td>\n",
       "      <td>115.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27 00:00:00-04:00</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>117.51</td>\n",
       "      <td>0.728783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.825032</td>\n",
       "      <td>-0.144715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>122.916686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.195564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.578138</td>\n",
       "      <td>3.538000</td>\n",
       "      <td>116.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28 00:00:00-04:00</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>116.87</td>\n",
       "      <td>1.119627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.978017</td>\n",
       "      <td>-1.022046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053102</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>122.588469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864079</td>\n",
       "      <td>114.078091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.065934</td>\n",
       "      <td>3.801579</td>\n",
       "      <td>111.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29 00:00:00-04:00</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>115.75</td>\n",
       "      <td>1.135187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.170475</td>\n",
       "      <td>-0.339153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385726</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>122.853416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907038</td>\n",
       "      <td>114.126793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.994893</td>\n",
       "      <td>4.062293</td>\n",
       "      <td>115.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30 00:00:00-04:00</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>115.04</td>\n",
       "      <td>1.440504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.296739</td>\n",
       "      <td>-1.350059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.042613</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>122.480291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338754</td>\n",
       "      <td>113.920253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.315379</td>\n",
       "      <td>4.018721</td>\n",
       "      <td>108.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21 00:00:00-04:00</th>\n",
       "      <td>ZS</td>\n",
       "      <td>198.08</td>\n",
       "      <td>0.591352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.829786</td>\n",
       "      <td>-0.767500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379954</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.197013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448228</td>\n",
       "      <td>198.700239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.048613</td>\n",
       "      <td>12.137150</td>\n",
       "      <td>193.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-22 00:00:00-04:00</th>\n",
       "      <td>ZS</td>\n",
       "      <td>199.44</td>\n",
       "      <td>0.544220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.856554</td>\n",
       "      <td>-0.447814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456718</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>216.628951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598410</td>\n",
       "      <td>198.614740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.903031</td>\n",
       "      <td>12.068543</td>\n",
       "      <td>196.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-23 00:00:00-04:00</th>\n",
       "      <td>ZS</td>\n",
       "      <td>204.64</td>\n",
       "      <td>0.813967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.923554</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572352</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>215.539892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>198.692201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.158932</td>\n",
       "      <td>12.107829</td>\n",
       "      <td>200.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-24 00:00:00-04:00</th>\n",
       "      <td>ZS</td>\n",
       "      <td>202.87</td>\n",
       "      <td>0.978322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.084911</td>\n",
       "      <td>1.043954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812322</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213.635586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.141134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.299986</td>\n",
       "      <td>11.635329</td>\n",
       "      <td>210.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25 00:00:00-04:00</th>\n",
       "      <td>ZS</td>\n",
       "      <td>201.09</td>\n",
       "      <td>1.045574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.298793</td>\n",
       "      <td>1.601637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920596</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>214.828624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.785796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.850464</td>\n",
       "      <td>10.807829</td>\n",
       "      <td>215.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204456 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Best config: {'lr': 4.390449033248878e-05, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3477694988633191, 'weight_decay': 0.0001801390872725824, 'batch_size': 16, 'window_size': 10, 'grad_clip_norm': 0.8393802881451728}\n",
    "\n",
    "config = {\n",
    "    \"lr\": 4.390449033248878e-05,\n",
    "    \"weight_decay\": 0.0001801390872725824,\n",
    "    \"hidden_size\": 256, # old was 256\n",
    "    \"num_layers\": 1, # old was 1\n",
    "    \"dropout\": 0.3477694988633191,\n",
    "    \"batch_size\": 16, # old was 16\n",
    "    \"window_size\": 5,\n",
    "    \"clip_size\": 0.8393802881451728,\n",
    "    \"attention_heads\": 4, #Deepseek R1 uses 128\n",
    "    \"epochs\": 20,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "}\n",
    "\n",
    "data_module = DataModule(training_data, window_size=config[\"window_size\"], batch_size=config[\"batch_size\"])\n",
    "config[\"input_size\"] = data_module.num_features\n",
    "\n",
    "# Instantiate the model\n",
    "model = TEMPUS(config,scaler=data_module.scaler).to(config[\"device\"])\n",
    "#model = torch.compile(model, backend=\"inductor\",mode=\"default\")\n",
    "model\n",
    "# Train Model\n",
    "history = model.train_model(data_module.train_loader, data_module.val_loader, data_module.test_loader, config[\"epochs\"])"
   ],
   "id": "b59222a40c0df26e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_fig = model.plot_training_history()\n",
    "training_fig.show()"
   ],
   "id": "c72276701361569f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Export the trained TEMPUS model\n",
    "script_path = model.export_model_to_torchscript(\n",
    "    save_path=\"Models/Echo_v1.0.pt\",\n",
    "    data_loader=data_module.test_loader,\n",
    "    device=\"cpu\"\n",
    ")"
   ],
   "id": "a121c469c60cd4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "# Randomly sample 50 tickers from the SnP600_tickers list\n",
    "sampled_tickers = random.sample(list(nasdaq_tickers), 10)\n",
    "initial_capital = 1000.0\n",
    "\n",
    "preds_dfs = []\n",
    "returns = []\n",
    "for idx, ticker in enumerate(sampled_tickers, start=1):\n",
    "    out_of_sample_data, raw_stock_data = TickerData(ticker, years=4, prediction_window=5).process_all()\n",
    "\n",
    "    # Check if raw_stock_data is NoneType, if so, skip this iteration\n",
    "    if out_of_sample_data is not None:\n",
    "        # Load the model and make predictions\n",
    "        preds_df = torchscript_predict(\n",
    "            model_path=\"Models/Tempus_v2.1.pt\",\n",
    "            input_df=out_of_sample_data,\n",
    "            device=\"cpu\",\n",
    "            window_size=50,\n",
    "            target_col=\"shifted_prices\"\n",
    "        )\n",
    "        preds_df = pd.merge(preds_df, raw_stock_data[['Open', 'High', 'Low', 'Volume','Close']], left_index=True, right_index=True, how='left')\n",
    "        preds_dfs.append(preds_df)\n",
    "\n",
    "        backtester = BackTesting(preds_df, ticker, initial_capital, pct_change_entry=0.05, pct_change_exit=0.03)\n",
    "        backtester.run_simulation()\n",
    "        bt_results = pd.DataFrame(backtester.pf.returns())\n",
    "        bt_results['cumulative_return'] = np.array(((1 + bt_results[0]).cumprod() - 1)*100)\n",
    "        bt_results['ticker'] = ticker\n",
    "        returns.append(bt_results)\n",
    "\n",
    "preds_dfs = pd.concat(preds_dfs, ignore_index=False)\n",
    "returns = pd.concat(returns, ignore_index=False)"
   ],
   "id": "501e7ec4239314d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate cumulative returns for each ticker and visualize them using Plotly\n",
    "# Group data by 'ticker' and calculate cumulative returns\n",
    "\n",
    "# Create an interactive plot using Plotly\n",
    "fig = px.line(\n",
    "    returns.reset_index(),\n",
    "    x='index',\n",
    "    y='cumulative_return',\n",
    "    color='ticker',\n",
    "    title='Cumulative Returns by Ticker',\n",
    "    labels={'index': 'Date', 'cumulative_return': 'Cumulative Return'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Return (%)',\n",
    "    showlegend=False,\n",
    "    height=600,\n",
    "    template='ggplot2',\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=False),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "last_returns = returns.groupby('ticker')['cumulative_return'].last()\n",
    "\n",
    "# Count positive and negative returns\n",
    "positive_count = sum(last_returns > 0)\n",
    "negative_count = sum(last_returns <= 0)\n",
    "total_count = len(last_returns)\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "last_returns_df = pd.DataFrame(last_returns).reset_index()\n",
    "last_returns_df.columns = ['Ticker', 'Final Return']\n",
    "last_returns_df.sort_values('Final Return', ascending=False, inplace=True)\n",
    "\n",
    "# Create a simple pie chart showing the proportion\n",
    "fig_pie = px.pie(\n",
    "    values=[positive_count, negative_count],\n",
    "    names=['Positive', 'Negative'],\n",
    "    title='Proportion of Tickers with Positive vs Negative Returns',\n",
    "    color_discrete_sequence=['green', 'red'],\n",
    "    template='ggplot2',\n",
    ")\n",
    "\n",
    "fig_pie.update_traces(textinfo='percent+label').update_layout(showlegend=False)\n",
    "fig_pie.show()\n",
    "\n",
    "# Calculate the proportion of tickers with positive returns\n",
    "if total_count > 0:\n",
    "    positive_proportion = positive_count / total_count\n",
    "    print(f\"Proportion of tickers with positive cumulative returns: {positive_proportion:.2%}\")\n",
    "    print(f\"Positive tickers: {positive_count} out of {total_count}\")\n",
    "    print(f\"Negative tickers: {negative_count} out of {total_count}\")\n",
    "else:\n",
    "    print(\"No ticker data available for analysis\")"
   ],
   "id": "8fe83c6e3200e788"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Randomly select a ticker from the `preds_dfs` object\n",
    "selected_ticker = random.choice(preds_dfs['Ticker'].unique())\n",
    "\n",
    "# Filter the `preds_dfs` DataFrame for the selected ticker\n",
    "preds_df = preds_dfs[preds_dfs['Ticker'] == selected_ticker]\n",
    "\n",
    "# Update the plot to reflect the filtered data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=preds_df['Predicted'], x=preds_df.index, mode='lines', name='Predicted', line=dict(color=\"Grey\")))\n",
    "fig.add_trace(go.Scatter(y=preds_df['Close'], x=preds_df.index, mode='lines', name='Close (Unshifted)', line=dict(color=\"Blue\")))\n",
    "fig.add_trace(go.Scatter(y=preds_df['Actual'], x=preds_df.index, mode='lines', name='Close (Shifted)'))\n",
    "fig.update_layout(\n",
    "    title=f'Prediction for {selected_ticker}',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price (USD)',\n",
    "    height=600,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02),\n",
    "    template='ggplot2'\n",
    ")\n",
    "fig.show()"
   ],
   "id": "11fcd6d12f84c611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from Components.BackTesting import BackTesting\n",
    "import pandas as pd\n",
    "ticker = 'PLTR'\n",
    "out_of_sample_data, raw_stock_data = TickerData(ticker, years=1, prediction_window=5,prediction_mode=True).process_all()\n",
    "\n",
    "preds_df = torchscript_predict(\n",
    "    model_path=\"Models/Tempus_v2.2.pt\",\n",
    "    input_df=out_of_sample_data,\n",
    "    device=\"cpu\",\n",
    "    window_size=50,\n",
    "    prediction_mode=True\n",
    ")\n",
    "preds_df = pd.merge(preds_df, raw_stock_data[['Open', 'High', 'Low', 'Volume','Close']], left_index=True, right_index=True, how='left')\n",
    "preds_df['shifted_prices'] = preds_df['Close'].shift(-abs(5))"
   ],
   "id": "1343bab47c7543d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=preds_df['Predicted'], x=preds_df.index, mode='lines', name='Predicted', line=dict(color=\"Grey\")))\n",
    "fig.add_trace(go.Scatter(y=preds_df['shifted_prices'], x=preds_df.index, mode='lines', name='Close (Shifted)', line=dict(color=\"Blue\")))\n",
    "fig.add_trace(go.Scatter(y=preds_df['Close'], x=preds_df.index, mode='lines', name='Close (Unshifted)', line=dict(color=\"Orange\")))\n",
    "fig.update_layout(template='ggplot2')\n",
    "fig.show()"
   ],
   "id": "56ac242dc8a22cd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import quantstats as qs\n",
    "\n",
    "backtester = BackTesting(preds_df, ticker, initial_capital, pct_change_entry=0.05,pct_change_exit=0.02)\n",
    "backtester.run_simulation()\n",
    "returns = backtester.pf.returns()\n",
    "returns.index = returns.index.tz_localize(None)\n",
    "\n",
    "#html = qs.reports.full(returns, \"NDAQ\")\n",
    "qs.reports.basic(returns, \"PLTR\",rf=0.0025, display=False)\n"
   ],
   "id": "e02ae8fe55d0f04a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee552b4fecdf72d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1545be14de42a86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_sentiment = training_data\n",
    "df_sentiment['total_count'] = df_sentiment['positive'] + df_sentiment['negative'] + df_sentiment['neutral']\n",
    "df_sentiment['pos_sent_ratio'] = df_sentiment['positive'] / df_sentiment['total_count']\n",
    "df_sentiment['neg_sent_ratio'] = df_sentiment['negative'] / df_sentiment['total_count']\n",
    "df_sentiment['neu_sent_ratio'] = df_sentiment['neutral'] / df_sentiment['total_count']\n",
    "df_sentiment['net_sentiment'] = (df_sentiment['positive'] - df_sentiment['negative']) / df_sentiment['total_count']\n",
    "df_sentiment['roll3_net'] = df_sentiment['net_sentiment'].rolling(3).mean()\n",
    "df_sentiment.fillna(0, inplace=True)\n",
    "df_sentiment"
   ],
   "id": "91e0f4915ca8bdf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ————————————\n",
    "# 1) Prepare your data\n",
    "# ————————————\n",
    "data_module = DataModule(training_data, window_size=10, batch_size=32,target_col='shifted_prices')\n",
    "# ————————————\n",
    "# 2) Define the LSTM model\n",
    "# ————————————\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, features)\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        # take the last layer’s hidden state\n",
    "        h_last = hn[-1]               # shape (batch, hidden_dim)\n",
    "        return self.out(h_last).squeeze(-1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" ) #mps\n",
    "model = LSTMRegressor(input_dim=data_module.num_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ————————————\n",
    "# 3) Training loop\n",
    "# ————————————\n",
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in data_module.train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        if pred.dim() > 1:\n",
    "            pred = pred[:, -1, 0] if pred.size(1) > 1 and pred.size(2) > 0 else pred.squeeze()\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_module.train_loader.dataset)\n",
    "    print(f\"Epoch {epoch:2d} — Train MSE: {avg_loss}\")"
   ],
   "id": "c5e2cf44a3af9d27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ————————————\n",
    "# 4) SHAP feature‐importance\n",
    "# ————————————\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Pull one batch from each loader\n",
    "#    Assumes each batch is a tuple (x, y) where\n",
    "#      x.shape == [batch_size, seq_len, n_features]\n",
    "train_batch, _ = next(iter(data_module.train_loader))\n",
    "test_batch,  _ = next(iter(data_module.test_loader))\n",
    "\n",
    "# Move to CPU / numpy for KernelExplainer\n",
    "# and infer seq_len & n_features\n",
    "train_np = train_batch.cpu().numpy()\n",
    "test_np  = test_batch.cpu().numpy()\n",
    "batch_size, seq_len, n_features = train_np.shape\n",
    "\n",
    "# 2) Build your background set (<=100 samples), flattened\n",
    "bg       = train_np[:100]                             # (B_bg, seq_len, n_feat)\n",
    "bg_flat  = bg.reshape(bg.shape[0], -1)                # (B_bg, seq_len*n_feat)\n",
    "\n",
    "# flatten all of test for explainer\n",
    "test_flat = test_np.reshape(test_np.shape[0], -1)     # (batch_size, seq_len*n_feat)\n",
    "\n",
    "# 3) Define a “flatten→3D→model→1D” wrapper\n",
    "def predict_flat(x_flat):\n",
    "    # x_flat: array shape (B, seq_len*n_feat) or (seq_len*n_feat,)\n",
    "    arr = np.array(x_flat)\n",
    "    arr = arr.reshape(-1, seq_len, n_features)        # back to (B, seq_len, n_feat)\n",
    "    t   = torch.from_numpy(arr).float().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(t).cpu().numpy().reshape(-1)      # (B,) scalar outputs\n",
    "    return out\n",
    "\n",
    "# 4) KernelExplainer on the flattened background\n",
    "explainer      = shap.KernelExplainer(predict_flat, bg_flat)\n",
    "\n",
    "# pick up to 50 test windows, but don’t assume you actually have 50\n",
    "n_explain = min(50, test_np.shape[0])\n",
    "shap_vals_flat = explainer.shap_values(test_flat[:n_explain])\n",
    "\n",
    "# if multi-output, grab the first list-element\n",
    "if isinstance(shap_vals_flat, list):\n",
    "    shap_vals_flat = shap_vals_flat[0]\n",
    "\n",
    "# now reshape using the correct n_explain\n",
    "shap_vals = np.array(shap_vals_flat).reshape(n_explain, seq_len, n_features)\n",
    "\n",
    "# 6) collapse the time axis and plot\n",
    "mean_abs_time = np.mean(np.abs(shap_vals), axis=0)  # (seq_len, n_feat)\n",
    "feat_imp      = mean_abs_time.mean(axis=0)         # (n_feat,)\n",
    "\n",
    "feature_names = list(training_data.drop(columns=[\"shifted_prices\"]).columns)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(y=feat_imp, x=feature_names))\n",
    "fig.update_layout(\n",
    "    title=\"Feature importance (averaged over time)\",\n",
    "    xaxis_title='Feature Names',\n",
    "    yaxis_title='Mean |SHAP value|',\n",
    "    template='ggplot2'\n",
    ")\n",
    "fig.show()"
   ],
   "id": "c974a6c4e3aa2734"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "financials = []\n",
    "current_date = datetime.today()\n",
    "past_date = current_date - timedelta(days=(365 * 2))\n",
    "for f in client.vx.list_stock_financials(ticker, filing_date_lte=current_date.strftime(\"%Y-%m-%d\"),\n",
    "                                         filing_date_gte=past_date.strftime(\"%Y-%m-%d\")):\n",
    "    financials.append(f)\n",
    "financials = pd.DataFrame(financials)\n",
    "\n",
    "import json  # only needed if your column contains JSON *strings*\n",
    "\n",
    "financials[\"financials\"] = financials[\"financials\"].apply(\n",
    "    lambda v: v if isinstance(v, dict) else json.loads(v)\n",
    ")\n",
    "flat = pd.json_normalize(\n",
    "    financials[\"financials\"].tolist()\n",
    ")\n",
    "flat_filtered = (\n",
    "    flat\n",
    "    .filter(like=\"value\")\n",
    "    #.dropna(axis=1, how=\"all\")   # drop cols that are all missing\n",
    ")\n",
    "flat_filtered.index = financials.index\n",
    "financials = financials.drop(columns=[\"financials\"]).join(flat_filtered)\n",
    "financials"
   ],
   "id": "3ace4ec1bffb93a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "#client.get_ticker_details(\"AAPL\")"
   ],
   "id": "6292067a42f6c958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "# %%\n",
    "# Import stock_data dataframe into an Azure SQL database table using SQLAlchemy\n",
    "#upload_data_sql(stock_data,\"SNP600_1day\")\n",
    "#SNP500_1day = fetch_sql_data('SNP500_1day')\n",
    "#SNP600_1day = fetch_sql_data('SNP600_1day')\n",
    "#russell2000_1day = fetch_sql_data('russell2000_1day')\n",
    "#dowjones_1day = fetch_sql_data('dowjones_1day')\n",
    "#nasdaq_1day = fetch_sql_data('nasdaq_1day')\n",
    "#stock_data = pd.concat([SNP500_1day, SNP600_1day, dowjones_1day, nasdaq_1day], ignore_index=True)\n",
    "# Remove duplicates based on the 'Date' and 'Ticker' columns\n",
    "#stock_data = stock_data[~stock_data.index.duplicated(keep='first')]\n",
    "# Before conversion\n",
    "#print(\"Column types before:\", [type(col).__name__ for col in training_data.columns])\n",
    "\n",
    "# Apply conversion\n",
    "#training_data.columns = [str(col) for col in training_data.columns]\n",
    "\n",
    "# After conversion\n",
    "#print(\"Column types after:\", [type(col).__name__ for col in training_data.columns])"
   ],
   "id": "a2eb65b6bd73e147"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25aa0ce5bb93cb4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6fff5bc7f164e105"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
