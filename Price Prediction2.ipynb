{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:54:17.953900Z",
     "start_time": "2025-03-26T01:54:13.691399Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Custom libraries\n",
    "from Components.ModelDataset import DataModule\n",
    "from Components.TrainModel import LSTMClassifierModel\n",
    "from Components.TickerData import TickerData\n",
    "from Components.BackTesting import BackTesting\n",
    "\n",
    "# Torch ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ae557-72e6-4a76-a93d-78e2381c05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Feature importance with SHAP values and plot\n",
    "#TODO: hyperparameter tuning\n",
    "#TODO: Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314fc1573f05b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc304bd6da39d466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:01:28.824432Z",
     "start_time": "2025-03-26T01:01:28.429412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the Wikipedia page title and section header\n",
    "tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")[4]\n",
    "# Clean up the dataframe\n",
    "tickers = tickers.iloc[:, [1]].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da234ad-7e05-4dd8-bc3c-9ea24c392f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['IONQ','QBTS','RGTI']\n",
    "training_dfs = []\n",
    "stocks_dfs = []\n",
    "for ticker in tickers:\n",
    "    training_data, raw_stock_data = TickerData(ticker,days=365).process_all()\n",
    "    training_dfs.append(training_data)\n",
    "    stocks_dfs.append(raw_stock_data)\n",
    "\n",
    "training_data = pd.concat(training_dfs, ignore_index=False)\n",
    "stock_data = pd.concat(stocks_dfs, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a8f78-fe7d-41e9-8e51-0a522e986489",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"Data/NASDAQ_100_TrainingData_2022-3-24_2025_03_24.csv\")\n",
    "training_data = training_data.set_index(training_data['Date']).drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a1096-cd23-467c-befe-284716d6b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv(\"Data/NASDAQ_100_StockData_2022-3-24_2025_03_24.csv\")\n",
    "stock_data = stock_data.set_index(stock_data['Date']).drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1305cef4d7a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:54:02.695126Z",
     "start_time": "2025-03-26T01:54:02.441411Z"
    }
   },
   "outputs": [],
   "source": [
    "data_module = DataModule(training_data, seq_length=10, batch_size=32)\n",
    "train_loader = data_module.train_loader\n",
    "train_labels = np.array(data_module.train_dataset.labels) \n",
    "classes = np.unique(train_labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "eval_loader = data_module.eval_loader\n",
    "test_loader = data_module.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c08f8808767bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:38:03.693219Z",
     "start_time": "2025-03-26T01:37:58.517626Z"
    }
   },
   "outputs": [],
   "source": [
    " # Define model parameters\n",
    "input_size = 33  # number of features\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = 3   # multiclass classification\n",
    "\n",
    "# Instantiate the unified model\n",
    "model = LSTMClassifierModel(input_size, hidden_size, num_layers, num_classes)\n",
    "#model = CNNClassifierModel(input_size, num_classes)\n",
    "#model = ConvLSTMClassifierModel(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Set up loss and optimizer\n",
    "unique_classes = np.unique(training_data['Target'].values)\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=training_data['Target'].values)\n",
    "class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "\n",
    "# Compute class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "history = model.train_model(train_loader, eval_loader, test_loader, criterion, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919aad42-5ba2-419a-b282-199fcbc5c682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:38:14.022943Z",
     "start_time": "2025-03-26T01:38:13.068719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get predictions on the entire dataset\n",
    "def get_predictions(model, df, seq_length=10):\n",
    "    predictions = []\n",
    "    dates = []\n",
    "    actuals = []\n",
    "    tickers = []\n",
    "    confidences = []\n",
    "\n",
    "    for i in range(seq_length, len(df)):\n",
    "        # Get sequence\n",
    "        sequence = df.iloc[i - seq_length:i].drop(columns=['Ticker']).values.astype(np.float32)\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Get date, actual value, and ticker for the current index\n",
    "        date = df.index[i]\n",
    "        actual = df['Target'].iloc[i]\n",
    "        ticker = df['Ticker'].iloc[i]\n",
    "\n",
    "        # Make prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(sequence_tensor)\n",
    "            probabilities = torch.softmax(output, dim=1)  # Convert outputs to probabilities\n",
    "            confidence, pred = torch.max(probabilities, 1)  # Get confidence and predicted class\n",
    "\n",
    "        predictions.append(pred.item())\n",
    "        confidences.append(confidence.item())  # Store the confidence score\n",
    "        dates.append(date)\n",
    "        actuals.append(actual)\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    # Create DataFrame with predictions\n",
    "    preds_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Ticker': tickers,\n",
    "        'Actual': actuals,\n",
    "        'Predicted': predictions,\n",
    "        'Confidence': confidences  # Add confidence scores to the DataFrame\n",
    "    })\n",
    "    preds_df['entry_signal'] = preds_df['Predicted'] == 2  # Buy signal\n",
    "    preds_df['exit_signal'] = preds_df['Predicted'] == 1  # Sell signal\n",
    "\n",
    "    return preds_df\n",
    "\n",
    "# Get predictions\n",
    "preds_df = get_predictions(model, training_data)\n",
    "\n",
    "merged_df = pd.merge(stock_data, preds_df, on=['Date', 'Ticker'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb1e7bec75b597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:38:07.672214Z",
     "start_time": "2025-03-26T01:38:07.638484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot training, evaluation and testing metrics\n",
    "def plot_training_history(history, y_true=None, y_pred=None):\n",
    "    # Create subplots for loss and accuracy\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Loss', 'F1 Score'))\n",
    "\n",
    "    # Plot losses\n",
    "    fig.add_trace(go.Scatter(y=history['train_loss'], name='Train Loss', line=dict(color='blue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=history['eval_loss'], name='Eval Loss', line=dict(color='orange')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=history['test_loss'], name='Test Loss', line=dict(color='green')), row=1, col=1)\n",
    "\n",
    "    # Plot f1\n",
    "    fig.add_trace(go.Scatter(y=history['eval_f1'], name='Eval F1 Score', line=dict(color='orange')), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(y=history['test_f1'], name='Test F1 Score', line=dict(color='green')), row=1, col=2)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Training Metrics',\n",
    "        xaxis_title='Epochs',\n",
    "        height=700,\n",
    "        template='plotly_white',\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02)\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"F1\", row=1, col=2)\n",
    "\n",
    "    return fig\n",
    "# Plot metrics\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7fb70-590e-42e7-b906-253a5a91d60b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:38:26.226964Z",
     "start_time": "2025-03-26T01:38:26.183982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a combined plot with stock prices and prediction markers\n",
    "def plot_combined_predictions(data, ticker):\n",
    "    # Filter for a particular ticker\n",
    "    if type(ticker) == str:\n",
    "        data = data[data['Ticker'] == ticker]\n",
    "    else:\n",
    "        return \"Ticker provided is not a valid value\"\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot stock price trend line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['Date'],\n",
    "        y=data['Close'],\n",
    "        mode='lines',\n",
    "        name='Stock Price',\n",
    "        line=dict(width=1)\n",
    "    ))\n",
    "\n",
    "    # Split signals by type and correctness\n",
    "    buy_signals = data[data['Predicted'] == 2]\n",
    "    sell_signals = data[data['Predicted'] == 1]\n",
    "    hold_signals = data[data['Predicted'] == 0]\n",
    "\n",
    "    # Correct/incorrect buy signals\n",
    "    correct_buy = buy_signals[buy_signals['Predicted'] == buy_signals['Actual']]\n",
    "    incorrect_buy = buy_signals[buy_signals['Predicted'] != buy_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect sell signals\n",
    "    correct_sell = sell_signals[sell_signals['Predicted'] == sell_signals['Actual']]\n",
    "    incorrect_sell = sell_signals[sell_signals['Predicted'] != sell_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect hold signals\n",
    "    correct_hold = hold_signals[hold_signals['Predicted'] == hold_signals['Actual']]\n",
    "    incorrect_hold = hold_signals[hold_signals['Predicted'] != hold_signals['Actual']]\n",
    "\n",
    "    # Plot buy signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_buy['Date'],\n",
    "        y=data.loc[correct_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=10, color='green')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_buy['Date'],\n",
    "        y=data.loc[incorrect_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot sell signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_sell['Date'],\n",
    "        y=data.loc[correct_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=10, color='red')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_sell['Date'],\n",
    "        y=data.loc[incorrect_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot hold signals (using a different symbol)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_hold['Date'],\n",
    "        y=data.loc[correct_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Hold Signal',\n",
    "        marker=dict(symbol='circle', size=8, color='blue')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_hold['Date'],\n",
    "        y=data.loc[incorrect_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Hold Signal',\n",
    "        marker=dict(symbol='circle', size=6, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'{ticker} Stock Price - Actual/Predicted Signals',\n",
    "        #xaxis_title='Date',\n",
    "        yaxis_title='Price (USD)',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Call the modified function\n",
    "plot_combined_predictions(merged_df, 'PLTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791757bc-255b-416a-8d6b-7fc72b79ba4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:32:44.814712Z",
     "start_time": "2025-03-26T01:32:43.658705Z"
    }
   },
   "outputs": [],
   "source": [
    "from Components.BackTesting import BackTesting\n",
    "import pandas as pd\n",
    "\n",
    "#merged_df = pd.read_csv('Data/NASDAQ_100_PredictictionsData.csv')\n",
    "\n",
    "initial_capital = 10000.0\n",
    "ticker = 'CRWD'\n",
    "backtester = BackTesting(merged_df, ticker, initial_capital)\n",
    "results, _ = backtester.run_simulation()\n",
    "trades_fig, value_fig, exposure_fig = backtester.plot_performance()\n",
    "trades_fig.show()\n",
    "value_fig.show()\n",
    "exposure_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc912d83ccedf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:49:50.683759Z",
     "start_time": "2025-03-25T23:49:50.682411Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871d1ece2811692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373858219796207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e12c4a43e47c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T01:54:24.676037Z",
     "start_time": "2025-03-26T01:54:24.131131Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "#from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from Components.TrainModel import TunableLSTMClassifier\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Define a training function for Ray Tune\n",
    "def train_lstm(config, input_size=33, num_classes=3, train_data=None, val_data=None, test_data=None):\n",
    "    # Set up device\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "    # Create model with the hyperparameter configuration\n",
    "    model = TunableLSTMClassifier({\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": config[\"hidden_size\"],\n",
    "        \"num_layers\": config[\"num_layers\"],\n",
    "        \"num_classes\": num_classes,\n",
    "        \"dropout_rate\": config[\"dropout_rate\"]\n",
    "    }).to(device)\n",
    "\n",
    "    # Set up data loaders\n",
    "    data_module = DataModule(train_data, seq_length=10, batch_size=config[\"batch_size\"])\n",
    "    train_loader = data_module.train_loader\n",
    "    val_loader = data_module.eval_loader\n",
    "    test_loader = data_module.test_loader\n",
    "\n",
    "    # Set up loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10):  # Limit epochs for tuning\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # Report metrics to Ray Tune\n",
    "        session.report({\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_loss\": val_loss / len(val_loader),\n",
    "            \"train_accuracy\": train_correct / train_total,\n",
    "            \"train_loss\": train_loss / len(train_loader),\n",
    "            \"epoch\": epoch\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbbfb01e2f4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize Ray\n",
    "ray.init()\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"hidden_size\": tune.choice([32, 64, 128, 256]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-3),\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128])\n",
    "}\n",
    "\n",
    "# Configure the ASHA scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    max_t=10,  # Maximum number of epochs\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Set up the tuner\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        partial(\n",
    "            train_lstm,\n",
    "            input_size=33,\n",
    "            num_classes=3,\n",
    "            train_data=training_data,\n",
    "            val_data=None,\n",
    "            test_data=None\n",
    "        ),\n",
    "        resources={\"cpu\": 2, \"gpu\": 0}  # Adjust based on your hardware\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        scheduler=scheduler,\n",
    "        num_samples=50,  # Number of hyperparameter combinations to try\n",
    "        trial_dirname_creator=lambda trial: f\"{trial.trainable_name}_{trial.trial_id[:4]}\"\n",
    "    ),\n",
    "    param_space=config\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "results = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd602774859b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Get the best hyperparameters\n",
    "best_result = results.get_best_result(\"val_accuracy\", \"max\")\n",
    "best_config = best_result.config\n",
    "print(\"Best config:\", best_config)\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "best_lr = best_config[\"lr\"]\n",
    "best_hidden_size = best_config[\"hidden_size\"]\n",
    "best_num_layers = best_config[\"num_layers\"]\n",
    "best_dropout = best_config[\"dropout_rate\"]\n",
    "best_weight_decay = best_config[\"weight_decay\"]\n",
    "best_batch_size = best_config[\"batch_size\"]\n",
    "\n",
    "# Plot results\n",
    "df_results = results.get_dataframe()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot learning rate vs validation accuracy\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(df_results[\"config/lr\"], df_results[\"val_accuracy\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "# Plot hidden size vs validation accuracy\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(df_results[\"config/hidden_size\"], df_results[\"val_accuracy\"])\n",
    "plt.xlabel(\"Hidden Size\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "# Plot num_layers vs validation accuracy\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(df_results[\"config/num_layers\"], df_results[\"val_accuracy\"])\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "# Plot dropout vs validation accuracy\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(df_results[\"config/dropout_rate\"], df_results[\"val_accuracy\"])\n",
    "plt.xlabel(\"Dropout Rate\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "# Plot weight decay vs validation accuracy\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(df_results[\"config/weight_decay\"], df_results[\"val_accuracy\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Weight Decay\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "# Plot batch size vs validation accuracy\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.scatter(df_results[\"config/batch_size\"], df_results[\"val_accuracy\"])\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e9e8dfd292942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0067a4686aadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62964a9774211cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticker.get_balance_sheet(freq='quarterly')\n",
    "#ticker.get_calendar()\n",
    "#ticker.get_cash_flow(freq='quarterly')\n",
    "#earnings_data = ticker.get_earnings_dates()\n",
    "#income_statement = ticker.get_income_stmt(freq='yearly').T\n",
    "#ticker.get_institutional_holders()\n",
    "#ticker.get_recommendations()\n",
    "#ticker.get_sustainability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ef9179077621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to fetch the options data for a given ticker symbol\n",
    "#def fetch_options_data(ticker_symbol):\n",
    "    #ticker = yf.Ticker(ticker_symbol)\n",
    "#    options_dates = ticker.options\n",
    "#    options_data = ticker.option_chain(date='2025-03-21')\n",
    "#    return options_data.calls, options_data.puts\n",
    "##ionq_stock_data = ionq_stock_data.sort_values(by='Date', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
