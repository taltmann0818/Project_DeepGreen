{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:35:59.051343Z",
     "start_time": "2025-03-30T20:35:59.042805Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Custom libraries\n",
    "from Components.TrainModel import DataModule, TEMPUS\n",
    "from Components.TickerData import TickerData\n",
    "from Components.BackTesting import BackTesting\n",
    "\n",
    "# Torch ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "b00ae557-72e6-4a76-a93d-78e2381c05e0",
   "metadata": {},
   "source": [
    "#TODO: Feature importance with SHAP values and plot\n",
    "#TODO: hyperparameter tuning\n",
    "#TODO: buy signals become if prediction > current by some delta (~5%). Reverse is sell (decrease by some delta). Senstitvity analysis should be conducted to compare this delta level\n",
    "#TODO: Use quantstats for a HTMl tearsheet\n",
    "#TODO: market-regime detector with Hiden-markov model\n",
    "#TODO: Add a Echo State Networks (ESN) layer to the model\n",
    "#TODO: randomly sample 50 tickers, run backtest for all of them, and plot. take average sharpe ratio, and other metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc304bd6da39d466",
   "metadata": {},
   "source": [
    "# Set the Wikipedia page title and section header\n",
    "tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")[4]\n",
    "# Clean up the dataframe\n",
    "tickers = tickers.iloc[:, [1]].to_numpy().flatten()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1da234ad-7e05-4dd8-bc3c-9ea24c392f5b",
   "metadata": {},
   "source": [
    "#tickers = ['IONQ','QBTS','RGTI']\n",
    "training_dfs = []\n",
    "stocks_dfs = []\n",
    "for ticker in tickers:\n",
    "    training_data, raw_stock_data = TickerData(ticker,years=10,prediction_window=5).process_all()\n",
    "    training_dfs.append(training_data)\n",
    "    stocks_dfs.append(raw_stock_data)\n",
    "\n",
    "training_data = pd.concat(training_dfs, ignore_index=False)\n",
    "stock_data = pd.concat(stocks_dfs, ignore_index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d3bf5fc-fc97-42e8-b637-bb2dea141680",
   "metadata": {},
   "source": [
    "#training_data.to_csv(\"Data/NASDAQ_100_TrainingData_v2.csv\", index=True)\n",
    "#stock_data.to_csv(\"Data/NASDAQ_100_StockData_v2.csv\", index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f39a8f78-fe7d-41e9-8e51-0a522e986489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:24:40.120552Z",
     "start_time": "2025-03-30T19:24:39.877726Z"
    }
   },
   "source": [
    "training_data = pd.read_csv(\"Data/NASDAQ_100_TrainingData_v2.csv\")\n",
    "training_data = training_data.set_index(training_data['Date']).drop(columns=['Date'])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e96a1096-cd23-467c-befe-284716d6b4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:24:40.903632Z",
     "start_time": "2025-03-30T19:24:40.710236Z"
    }
   },
   "source": [
    "stock_data = pd.read_csv(\"Data/NASDAQ_100_StockData_v2.csv\")\n",
    "stock_data = stock_data.set_index(stock_data['Date']).drop(columns=['Date'])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "788c08f8808767bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:24:30.649846Z",
     "start_time": "2025-03-30T19:24:43.987144Z"
    }
   },
   "source": [
    "# Automatically get the number of features given my data_module object\n",
    "\n",
    "#Best config: {'lr': 4.390449033248878e-05, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3477694988633191, 'weight_decay': 0.0001801390872725824, 'batch_size': 16, 'window_size': 10, 'grad_clip_norm': 0.8393802881451728}\n",
    "\n",
    "config = {\n",
    "    \"lr\": 4.390449033248878e-05,\n",
    "    \"weight_decay\": 0.0001801390872725824,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 1,\n",
    "    \"dropout\": 0.3477694988633191,\n",
    "    \"batch_size\": 16,\n",
    "    \"window_size\": 50,\n",
    "    \"clip_size\": 0.8393802881451728,\n",
    "    \"epochs\": 20,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "data_module = DataModule(training_data, window_size=config[\"window_size\"], batch_size=config[\"batch_size\"])\n",
    "config[\"input_size\"] = data_module.num_features\n",
    "\n",
    "# Instantiate the model\n",
    "model = TEMPUS(config)\n",
    "# Set up loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "# Train Model\n",
    "history = model.train_model(data_module.train_loader, data_module.test_loader, criterion, optimizer, config[\"epochs\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffde09a0af6f48adac44e251b86d0660"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best MAPE: 4.04%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:42:39.449075Z",
     "start_time": "2025-03-30T20:42:39.048769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "def export_model_to_onnx(model, save_name, data_loader, device, dynamic_axes=False):\n",
    "    \"\"\"\n",
    "    Exports a model to ONNX format with support for static and dynamic axes.\n",
    "\n",
    "    Parameters:\n",
    "        model: The PyTorch model to export.\n",
    "        save_name (str): File name for the exported ONNX file (excluding extension).\n",
    "        data_loader: DataLoader containing sample input data.\n",
    "        device (str): Device on which the model operates, e.g., 'cpu' or 'cuda'.\n",
    "        dynamic_axes (bool): Whether to export with dynamic axes (default: False).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch a sample input tensor from the DataLoader\n",
    "        example_inputs, _ = next(iter(data_loader))\n",
    "        example_inputs = example_inputs.to(device)\n",
    "\n",
    "        # Define ONNX file path\n",
    "        save_path = os.path.join(\"Models\", f\"{save_name}.onnx\")\n",
    "\n",
    "        # Dynamic axes configuration (optional)\n",
    "        dynamic_axes_dict = None\n",
    "        if dynamic_axes:\n",
    "            dynamic_axes_dict = {\n",
    "                'input': {0: 'batch_size', 1: 'seq_len'},  # Dynamic batch and sequence length for input\n",
    "                'output': {0: 'batch_size', 1: 'seq_len'}  # Dynamic batch and sequence length for output\n",
    "            }\n",
    "\n",
    "        # Export to ONNX format\n",
    "        torch.onnx.export(\n",
    "            model=model,\n",
    "            args=example_inputs,  # Sample input tensor\n",
    "            f=save_path,\n",
    "            input_names=[\"input\"],  # Name for the model input\n",
    "            output_names=[\"output\"],  # Name for the model output\n",
    "            export_params=True,  # Include the model parameters in the ONNX file\n",
    "            opset_version=16,  # ONNX version to export (ensure compatibility with your project)\n",
    "            dynamic_axes=dynamic_axes_dict,  # Dynamic axis configuration\n",
    "        )\n",
    "\n",
    "        # Verify the ONNX model\n",
    "        onnx_model = onnx.load(save_path)\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        print(f\"Model successfully exported to {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model to ONNX: {str(e)}\")\n",
    "\n",
    "# Usage Example:\n",
    "export_model_to_onnx(model, \"TEMPUS_v3\", data_module.test_loader, device, dynamic_axes=True)"
   ],
   "id": "e2a5055a963e2d6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas Altmann\\PycharmProjects\\Project_DeepGreen\\Components\\TrainModel.py:79: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len % factor != 0:\n",
      "C:\\Users\\Thomas Altmann\\PycharmProjects\\Project_DeepGreen\\Components\\TrainModel.py:128: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if features == lstm_features.size(2):  # If dimensions match\n",
      "C:\\Users\\Thomas Altmann\\anaconda3\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4244: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully exported to Models\\TEMPUS_v3.onnx\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:55:26.650226Z",
     "start_time": "2025-03-30T20:55:26.569357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "data_module = DataModule(training_data, window_size=50, batch_size=16)\n",
    "example_inputs, _ = next(iter(data_module.test_loader))\n",
    "\n",
    "onnx_inputs = [tensor.numpy(force=True) for tensor in example_inputs]\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"Models/TEMPUS_v3.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "onnxruntime_input = {input_arg.name: input_value for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)}\n",
    "\n",
    "# ONNX Runtime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]\n"
   ],
   "id": "d2c834ff5cf11888",
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: input Got: 2 Expected: 3 Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgument\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m onnxruntime_input \u001B[38;5;241m=\u001B[39m {input_arg\u001B[38;5;241m.\u001B[39mname: input_value \u001B[38;5;28;01mfor\u001B[39;00m input_arg, input_value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(ort_session\u001B[38;5;241m.\u001B[39mget_inputs(), onnx_inputs)}\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# ONNX Runtime returns a list of outputs\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m onnxruntime_outputs \u001B[38;5;241m=\u001B[39m ort_session\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28;01mNone\u001B[39;00m, onnxruntime_input)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:266\u001B[0m, in \u001B[0;36mSession.run\u001B[1;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[0;32m    264\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sess\u001B[38;5;241m.\u001B[39mrun(output_names, input_feed, run_options)\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[1;31mInvalidArgument\u001B[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: input Got: 2 Expected: 3 Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:55:39.281515Z",
     "start_time": "2025-03-30T20:55:39.274572Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3cf01a93de94bd2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "919aad42-5ba2-419a-b282-199fcbc5c682",
   "metadata": {},
   "source": [
    "# Plot training metrics\n",
    "training_fig = model.plot_training_history(training_data)\n",
    "training_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecdb1e7bec75b597",
   "metadata": {},
   "source": [
    "# Get predictions\n",
    "preds_df = model.get_predictions(training_data)\n",
    "merged_df = pd.merge(stock_data, preds_df, on=['Date', 'Ticker'], how='inner')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93f7fb70-590e-42e7-b906-253a5a91d60b",
   "metadata": {},
   "source": [
    "# Create a combined plot with stock prices and prediction markers\n",
    "def plot_combined_predictions(data, ticker):\n",
    "    # Filter for a particular ticker\n",
    "    if type(ticker) == str:\n",
    "        data = data[data['Ticker'] == ticker]\n",
    "    else:\n",
    "        return \"Ticker provided is not a valid value\"\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot stock price trend line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['Date'],\n",
    "        y=data['Close'],\n",
    "        mode='lines',\n",
    "        name='Stock Price',\n",
    "        line=dict(width=1)\n",
    "    ))\n",
    "\n",
    "    # Split signals by type and correctness\n",
    "    buy_signals = data[data['Predicted'] == 2]\n",
    "    sell_signals = data[data['Predicted'] == 1]\n",
    "    hold_signals = data[data['Predicted'] == 0]\n",
    "\n",
    "    # Correct/incorrect buy signals\n",
    "    correct_buy = buy_signals[buy_signals['Predicted'] == buy_signals['Actual']]\n",
    "    incorrect_buy = buy_signals[buy_signals['Predicted'] != buy_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect sell signals\n",
    "    correct_sell = sell_signals[sell_signals['Predicted'] == sell_signals['Actual']]\n",
    "    incorrect_sell = sell_signals[sell_signals['Predicted'] != sell_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect hold signals\n",
    "    correct_hold = hold_signals[hold_signals['Predicted'] == hold_signals['Actual']]\n",
    "    incorrect_hold = hold_signals[hold_signals['Predicted'] != hold_signals['Actual']]\n",
    "\n",
    "    # Plot buy signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_buy['Date'],\n",
    "        y=data.loc[correct_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=10, color='green')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_buy['Date'],\n",
    "        y=data.loc[incorrect_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot sell signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_sell['Date'],\n",
    "        y=data.loc[correct_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=10, color='red')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_sell['Date'],\n",
    "        y=data.loc[incorrect_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot hold signals (using a different symbol)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_hold['Date'],\n",
    "        y=data.loc[correct_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Hold Signal',\n",
    "        marker=dict(symbol='circle', size=8, color='blue')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_hold['Date'],\n",
    "        y=data.loc[incorrect_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Hold Signal',\n",
    "        marker=dict(symbol='circle', size=6, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'{ticker} Stock Price - Actual/Predicted Signals',\n",
    "        #xaxis_title='Date',\n",
    "        yaxis_title='Price (USD)',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Call the modified function\n",
    "plot_combined_predictions(merged_df, 'PLTR')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "791757bc-255b-416a-8d6b-7fc72b79ba4f",
   "metadata": {},
   "source": [
    "from Components.BackTesting import BackTesting\n",
    "import pandas as pd\n",
    "\n",
    "#merged_df = pd.read_csv('Data/NASDAQ_100_PredictictionsData.csv')\n",
    "\n",
    "initial_capital = 10000.0\n",
    "ticker = 'PLTR'\n",
    "backtester = BackTesting(merged_df, ticker, initial_capital)\n",
    "results, _ = backtester.run_simulation()\n",
    "trades_fig, value_fig, exposure_fig = backtester.plot_performance()\n",
    "trades_fig.show()\n",
    "value_fig.show()\n",
    "exposure_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34fc912d83ccedf8",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7871d1ece2811692",
   "metadata": {},
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, dilation, padding, dropout=0.2):\n",
    "        super(TCNBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm1 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=output_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm2 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu2 = nn.ReLU()  # Added missing relu2 activation\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Residual connection if dimensions don't match\n",
    "        self.residual = nn.Conv1d(input_dim, output_dim, 1) if input_dim != output_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First conv block\n",
    "        # Residual input\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        # Second conv block\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.relu2(out)  # Correctly use relu2\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        # Return to original shape\n",
    "        # Add the residual and pass through final activation\n",
    "        return self.relu1(out + residual)  # Fixed to use relu1 for the final activation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e373858219796207",
   "metadata": {},
   "source": [
    "class EchoStateNetwork(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9,\n",
    "                 sparsity=0.1, noise=0.001, bidirectional=False):\n",
    "        super(EchoStateNetwork, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.noise = noise\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Input weights (fixed)\n",
    "        self.register_buffer('W_in', self._initialize_input_weights())\n",
    "\n",
    "        # Reservoir weights (fixed)\n",
    "        self.register_buffer('W', self._initialize_reservoir_weights())\n",
    "\n",
    "        # Output weights (trainable)\n",
    "        self.W_out = nn.Linear(reservoir_size, output_size)\n",
    "\n",
    "        if bidirectional:\n",
    "            # Second set of weights for backward direction\n",
    "            self.register_buffer('W_in_reverse', self._initialize_input_weights())\n",
    "            self.register_buffer('W_reverse', self._initialize_reservoir_weights())\n",
    "            self.W_out_reverse = nn.Linear(reservoir_size, output_size)\n",
    "            # Combined output\n",
    "            self.W_combined = nn.Linear(output_size * 2, output_size)\n",
    "\n",
    "    def _initialize_input_weights(self):\n",
    "        W_in = torch.zeros(self.reservoir_size, self.input_size)\n",
    "        W_in = torch.nn.init.xavier_uniform_(W_in)\n",
    "        return W_in\n",
    "\n",
    "    def _initialize_reservoir_weights(self):\n",
    "        # Create sparse matrix\n",
    "        W = torch.zeros(self.reservoir_size, self.reservoir_size)\n",
    "        num_connections = int(self.sparsity * self.reservoir_size * self.reservoir_size)\n",
    "        indices = torch.randperm(self.reservoir_size * self.reservoir_size)[:num_connections]\n",
    "        rows = indices // self.reservoir_size\n",
    "        cols = indices % self.reservoir_size\n",
    "        values = torch.randn(num_connections)\n",
    "        W[rows, cols] = values\n",
    "\n",
    "        # Scale to desired spectral radius\n",
    "        eigenvalues = torch.linalg.eigvals(W)\n",
    "        max_eigenvalue = torch.max(torch.abs(eigenvalues))\n",
    "        W = W * (self.spectral_radius / max_eigenvalue)\n",
    "        return W\n",
    "\n",
    "    def _reservoir_step(self, x, h_prev, W_in, W):\n",
    "        \"\"\"Execute one step of the reservoir\"\"\"\n",
    "        # h_new = tanh(W_in @ x + W @ h_prev + noise)\n",
    "        h_new = torch.tanh(torch.mm(x, W_in.t()) + torch.mm(h_prev, W.t()) +\n",
    "                           self.noise * torch.randn(h_prev.shape, device=h_prev.device))\n",
    "        return h_new\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Forward pass\n",
    "        h = torch.zeros(batch_size, self.reservoir_size, device=x.device)\n",
    "        outputs_forward = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h = self._reservoir_step(x[:, t], h, self.W_in, self.W)\n",
    "            outputs_forward.append(self.W_out(h))\n",
    "\n",
    "        outputs_forward = torch.stack(outputs_forward, dim=1)  # (batch_size, seq_len, output_size)\n",
    "\n",
    "        if not self.bidirectional:\n",
    "            return outputs_forward\n",
    "\n",
    "        # Backward pass for bidirectional ESN\n",
    "        h_reverse = torch.zeros(batch_size, self.reservoir_size, device=x.device)\n",
    "        outputs_reverse = []\n",
    "\n",
    "        for t in range(seq_len - 1, -1, -1):\n",
    "            h_reverse = self._reservoir_step(x[:, t], h_reverse, self.W_in_reverse, self.W_reverse)\n",
    "            outputs_reverse.insert(0, self.W_out_reverse(h_reverse))\n",
    "\n",
    "        outputs_reverse = torch.stack(outputs_reverse, dim=1)  # (batch_size, seq_len, output_size)\n",
    "\n",
    "        # Combine forward and backward outputs\n",
    "        combined = torch.cat((outputs_forward, outputs_reverse), dim=2)\n",
    "        return self.W_combined(combined)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8b0067a4686aadf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62964a9774211cfa",
   "metadata": {},
   "source": [
    "#ticker.get_balance_sheet(freq='quarterly')\n",
    "#ticker.get_calendar()\n",
    "#ticker.get_cash_flow(freq='quarterly')\n",
    "#earnings_data = ticker.get_earnings_dates()\n",
    "#income_statement = ticker.get_income_stmt(freq='yearly').T\n",
    "#ticker.get_institutional_holders()\n",
    "#ticker.get_recommendations()\n",
    "#ticker.get_sustainability()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "387ef9179077621f",
   "metadata": {},
   "source": [
    "# define a function to fetch the options data for a given ticker symbol\n",
    "#def fetch_options_data(ticker_symbol):\n",
    "    #ticker = yf.Ticker(ticker_symbol)\n",
    "#    options_dates = ticker.options\n",
    "#    options_data = ticker.option_chain(date='2025-03-21')\n",
    "#    return options_data.calls, options_data.puts\n",
    "##ionq_stock_data = ionq_stock_data.sort_values(by='Date', ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
