{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T22:15:23.101757Z",
     "start_time": "2025-03-30T22:15:18.124354Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom libraries\n",
    "from Components.TrainModel import DataModule, TEMPUS\n",
    "from Components.TickerData import TickerData\n",
    "from Components.BackTesting import BackTesting\n",
    "\n",
    "# Torch ML libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b00ae557-72e6-4a76-a93d-78e2381c05e0",
   "metadata": {},
   "source": [
    "#TODO: Feature importance with SHAP values and plot\n",
    "#TODO: hyperparameter tuning\n",
    "#TODO: buy signals become if prediction > current by some delta (~5%). Reverse is sell (decrease by some delta). Senstitvity analysis should be conducted to compare this delta level\n",
    "#TODO: Use quantstats for a HTMl tearsheet\n",
    "#TODO: market-regime detector with Hiden-markov model\n",
    "#TODO: Add a Echo State Networks (ESN) layer to the model\n",
    "#TODO: randomly sample 50 tickers, run backtest for all of them, and plot. take average sharpe ratio, and other metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc304bd6da39d466",
   "metadata": {},
   "source": [
    "# Set the Wikipedia page title and section header\n",
    "tickers = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")[4]\n",
    "# Clean up the dataframe\n",
    "tickers = tickers.iloc[:, [1]].to_numpy().flatten()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1da234ad-7e05-4dd8-bc3c-9ea24c392f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T22:30:18.229004Z",
     "start_time": "2025-03-30T22:30:17.736395Z"
    }
   },
   "source": [
    "tickers = ['IONQ','QBTS','RGTI']\n",
    "training_dfs = []\n",
    "stocks_dfs = []\n",
    "for ticker in tickers:\n",
    "    training_data, raw_stock_data = TickerData(ticker,years=10,prediction_window=5).process_all()\n",
    "    training_dfs.append(training_data)\n",
    "    stocks_dfs.append(raw_stock_data)\n",
    "\n",
    "training_data = pd.concat(training_dfs, ignore_index=False)\n",
    "stock_data = pd.concat(stocks_dfs, ignore_index=False)\n",
    "training_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          Ticker     ema_20     ema_50    ema_100  stoch_rsi  \\\n",
       "Date                                                                           \n",
       "2021-02-10 00:00:00-05:00   IONQ  11.638654  11.321118  11.110774   0.072037   \n",
       "2021-02-11 00:00:00-05:00   IONQ  11.651164  11.338721  11.123828   0.000000   \n",
       "2021-02-12 00:00:00-05:00   IONQ  11.665338  11.356811  11.137218   0.000000   \n",
       "2021-02-16 00:00:00-05:00   IONQ  11.668640  11.370269  11.148362   0.078767   \n",
       "2021-02-17 00:00:00-05:00   IONQ  11.682102  11.387513  11.161464   0.815016   \n",
       "...                          ...        ...        ...        ...        ...   \n",
       "2025-03-17 00:00:00-04:00   RGTI   9.695960   9.919605   8.389624   1.000000   \n",
       "2025-03-18 00:00:00-04:00   RGTI   9.749678   9.932954   8.426661   0.829082   \n",
       "2025-03-19 00:00:00-04:00   RGTI   9.764470   9.931857   8.455935   0.967932   \n",
       "2025-03-20 00:00:00-04:00   RGTI   9.690711   9.894922   8.466511   0.748454   \n",
       "2025-03-21 00:00:00-04:00   RGTI   9.631596   9.862572   8.478461   0.889403   \n",
       "\n",
       "                               macd   Close  shifted_prices  \n",
       "Date                                                         \n",
       "2021-02-10 00:00:00-05:00  0.213186  11.880           12.24  \n",
       "2021-02-11 00:00:00-05:00  0.197668  11.770           12.71  \n",
       "2021-02-12 00:00:00-05:00  0.185650  11.800           12.75  \n",
       "2021-02-16 00:00:00-05:00  0.166141  11.700           12.14  \n",
       "2021-02-17 00:00:00-05:00  0.157738  11.810           14.44  \n",
       "...                             ...     ...             ...  \n",
       "2025-03-17 00:00:00-04:00 -0.390645  11.160            9.78  \n",
       "2025-03-18 00:00:00-04:00 -0.301039  10.260            9.82  \n",
       "2025-03-19 00:00:00-04:00 -0.255723   9.905            9.18  \n",
       "2025-03-20 00:00:00-04:00 -0.290297   8.990            8.47  \n",
       "2025-03-21 00:00:00-04:00 -0.307694   9.070            8.15  \n",
       "\n",
       "[3038 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>ema_50</th>\n",
       "      <th>ema_100</th>\n",
       "      <th>stoch_rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>Close</th>\n",
       "      <th>shifted_prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-10 00:00:00-05:00</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>11.638654</td>\n",
       "      <td>11.321118</td>\n",
       "      <td>11.110774</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.213186</td>\n",
       "      <td>11.880</td>\n",
       "      <td>12.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11 00:00:00-05:00</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>11.651164</td>\n",
       "      <td>11.338721</td>\n",
       "      <td>11.123828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197668</td>\n",
       "      <td>11.770</td>\n",
       "      <td>12.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-12 00:00:00-05:00</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>11.665338</td>\n",
       "      <td>11.356811</td>\n",
       "      <td>11.137218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185650</td>\n",
       "      <td>11.800</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-16 00:00:00-05:00</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>11.668640</td>\n",
       "      <td>11.370269</td>\n",
       "      <td>11.148362</td>\n",
       "      <td>0.078767</td>\n",
       "      <td>0.166141</td>\n",
       "      <td>11.700</td>\n",
       "      <td>12.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17 00:00:00-05:00</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>11.682102</td>\n",
       "      <td>11.387513</td>\n",
       "      <td>11.161464</td>\n",
       "      <td>0.815016</td>\n",
       "      <td>0.157738</td>\n",
       "      <td>11.810</td>\n",
       "      <td>14.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-17 00:00:00-04:00</th>\n",
       "      <td>RGTI</td>\n",
       "      <td>9.695960</td>\n",
       "      <td>9.919605</td>\n",
       "      <td>8.389624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.390645</td>\n",
       "      <td>11.160</td>\n",
       "      <td>9.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-18 00:00:00-04:00</th>\n",
       "      <td>RGTI</td>\n",
       "      <td>9.749678</td>\n",
       "      <td>9.932954</td>\n",
       "      <td>8.426661</td>\n",
       "      <td>0.829082</td>\n",
       "      <td>-0.301039</td>\n",
       "      <td>10.260</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-19 00:00:00-04:00</th>\n",
       "      <td>RGTI</td>\n",
       "      <td>9.764470</td>\n",
       "      <td>9.931857</td>\n",
       "      <td>8.455935</td>\n",
       "      <td>0.967932</td>\n",
       "      <td>-0.255723</td>\n",
       "      <td>9.905</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-20 00:00:00-04:00</th>\n",
       "      <td>RGTI</td>\n",
       "      <td>9.690711</td>\n",
       "      <td>9.894922</td>\n",
       "      <td>8.466511</td>\n",
       "      <td>0.748454</td>\n",
       "      <td>-0.290297</td>\n",
       "      <td>8.990</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-21 00:00:00-04:00</th>\n",
       "      <td>RGTI</td>\n",
       "      <td>9.631596</td>\n",
       "      <td>9.862572</td>\n",
       "      <td>8.478461</td>\n",
       "      <td>0.889403</td>\n",
       "      <td>-0.307694</td>\n",
       "      <td>9.070</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3038 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "3d3bf5fc-fc97-42e8-b637-bb2dea141680",
   "metadata": {},
   "source": [
    "#training_data.to_csv(\"Data/NASDAQ_100_TrainingData_v2.csv\", index=True)\n",
    "#stock_data.to_csv(\"Data/NASDAQ_100_StockData_v2.csv\", index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f39a8f78-fe7d-41e9-8e51-0a522e986489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:24:40.120552Z",
     "start_time": "2025-03-30T19:24:39.877726Z"
    }
   },
   "source": [
    "training_data = pd.read_csv(\"Data/NASDAQ_100_TrainingData_v2.csv\")\n",
    "training_data = training_data.set_index(training_data['Date']).drop(columns=['Date'])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e96a1096-cd23-467c-befe-284716d6b4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:24:40.903632Z",
     "start_time": "2025-03-30T19:24:40.710236Z"
    }
   },
   "source": [
    "stock_data = pd.read_csv(\"Data/NASDAQ_100_StockData_v2.csv\")\n",
    "stock_data = stock_data.set_index(stock_data['Date']).drop(columns=['Date'])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "788c08f8808767bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T20:24:30.649846Z",
     "start_time": "2025-03-30T19:24:43.987144Z"
    }
   },
   "source": [
    "# Automatically get the number of features given my data_module object\n",
    "\n",
    "#Best config: {'lr': 4.390449033248878e-05, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3477694988633191, 'weight_decay': 0.0001801390872725824, 'batch_size': 16, 'window_size': 10, 'grad_clip_norm': 0.8393802881451728}\n",
    "\n",
    "config = {\n",
    "    \"lr\": 4.390449033248878e-05,\n",
    "    \"weight_decay\": 0.0001801390872725824,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 1,\n",
    "    \"dropout\": 0.3477694988633191,\n",
    "    \"batch_size\": 16,\n",
    "    \"window_size\": 50,\n",
    "    \"clip_size\": 0.8393802881451728,\n",
    "    \"epochs\": 20,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "data_module = DataModule(training_data, window_size=config[\"window_size\"], batch_size=config[\"batch_size\"])\n",
    "config[\"input_size\"] = data_module.num_features\n",
    "\n",
    "# Instantiate the model\n",
    "model = TEMPUS(config)\n",
    "# Set up loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "# Train Model\n",
    "history = model.train_model(data_module.train_loader, data_module.test_loader, criterion, optimizer, config[\"epochs\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffde09a0af6f48adac44e251b86d0660"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best MAPE: 4.04%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "def export_model_to_torchscript(model, save_path, data_loader, device):\n",
    "    \"\"\"\n",
    "    Exports a PyTorch model to TorchScript format.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The trained PyTorch model to export.\n",
    "        save_path (str): File name for the saved TorchScript model (including extension, e.g., 'TEMPUS_v3.pt').\n",
    "        data_loader (DataLoader): DataLoader containing sample input data to trace the model.\n",
    "        device (str): Device on which the model operates, e.g., 'cpu' or 'cuda'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Fetch a sample input tensor from DataLoader\n",
    "        example_inputs, _ = next(iter(data_loader))\n",
    "        example_inputs = example_inputs.to(device)\n",
    "\n",
    "        # Export model to TorchScript using tracing\n",
    "        scripted_model = torch.jit.trace(model.to(device), example_inputs)\n",
    "\n",
    "        # Save the TorchScript model\n",
    "        torch.jit.save(scripted_model, save_path)\n",
    "\n",
    "        print(f\"Model successfully exported and saved to {save_path}\")\n",
    "        return save_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model to TorchScript: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Export the trained TEMPUS model\n",
    "script_path = export_model_to_torchscript(\n",
    "    model=model,\n",
    "    save_name=\"tempus_model_torchscript\",\n",
    "    data_loader=data_module.test_loader,\n",
    "    device=config[\"device\"]\n",
    ")\n"
   ],
   "id": "ebd8c392578867a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "def load_and_predict_with_torchscript(script_path, out_of_sample_data, device, window_size):\n",
    "    \"\"\"\n",
    "    Loads a TorchScript model and uses it for prediction on out-of-sample data.\n",
    "\n",
    "    Parameters:\n",
    "        script_path (str): Path to the saved TorchScript model\n",
    "        out_of_sample_data (DataFrame): New data for prediction\n",
    "        device (str): Device on which to run inference\n",
    "        window_size (int): Window size used during training\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predictions from the model\n",
    "    \"\"\"\n",
    "    # Load the TorchScript model\n",
    "    loaded_model = torch.jit.load(script_path)\n",
    "    loaded_model.to(device)\n",
    "    loaded_model.eval()\n",
    "\n",
    "    print(\"TorchScript model loaded successfully\")\n",
    "\n",
    "    # Prepare the out-of-sample data\n",
    "    # Assuming similar preprocessing as in the DataModule class\n",
    "\n",
    "    # If using same format as your DataModule\n",
    "    from Components.TrainModel import DataModule\n",
    "    data_module_test = DataModule(\n",
    "        out_of_sample_data,\n",
    "        window_size=window_size,\n",
    "        batch_size=1,  # For prediction, we can use batch size of 1\n",
    "        train_ratio=0  # All data is for testing\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_module_test.test_loader:\n",
    "            X = X.to(device)\n",
    "            output = loaded_model(X)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    all_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# Example usage with out-of-sample data\n",
    "# Assuming you have some out-of-sample data for testing\n",
    "# For this example, I'll use a portion of the test data as \"out-of-sample\"\n",
    "\n",
    "# Get out-of-sample data (this is just an example, replace with your actual out-of-sample data)\n",
    "# One option is to use the most recent data that wasn't used in training\n",
    "ticker = \"AAPL\"  # Replace with your ticker of interest\n",
    "out_of_sample_data, raw_stock_data = TickerData(ticker, years=1, prediction_window=5).process_all()\n",
    "\n",
    "# Load the model and make predictions\n",
    "predictions = load_and_predict_with_torchscript(\n",
    "    script_path=script_path,\n",
    "    out_of_sample_data=out_of_sample_data,\n",
    "    device=config[\"device\"],\n",
    "    window_size=config[\"window_size\"]\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(predictions)} predictions for {ticker}\")\n",
    "\n",
    "# Visualize the predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(predictions[:, 0], label='Predicted Price Change (%)')\n",
    "plt.title(f'Price Change Predictions for {ticker} using TorchScript Model')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Price Change (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "67cebfee2dae8fbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:24:13.316292Z",
     "start_time": "2025-03-31T00:24:13.310470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add trading signals based on predictions\n",
    "training_data['entry_signal'] = np.where(\n",
    "    (training_data['Predicted'].notna()) &\n",
    "    (training_data['Predicted'] > training_data['Close'] * 1.05),  # 5% increase prediction\n",
    "    1,  # Buy signal\n",
    "    0\n",
    ")\n",
    "\n",
    "training_data['exit_signal'] = np.where(\n",
    "    (training_data['Predicted'].notna()) &\n",
    "    (training_data['Predicted'] < training_data['Close'] * 0.95),  # 5% decrease prediction\n",
    "    1,  # Sell signal\n",
    "    0\n",
    ")\n"
   ],
   "id": "3cf01a93de94bd2d",
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "ecdb1e7bec75b597",
   "metadata": {},
   "source": [
    "# Get predictions\n",
    "preds_df = model.get_predictions(training_data)\n",
    "merged_df = pd.merge(stock_data, preds_df, on=['Date', 'Ticker'], how='inner')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93f7fb70-590e-42e7-b906-253a5a91d60b",
   "metadata": {},
   "source": [
    "# Create a combined plot with stock prices and prediction markers\n",
    "def plot_combined_predictions(data, ticker):\n",
    "    # Filter for a particular ticker\n",
    "    if type(ticker) == str:\n",
    "        data = data[data['Ticker'] == ticker]\n",
    "    else:\n",
    "        return \"Ticker provided is not a valid value\"\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot stock price trend line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['Date'],\n",
    "        y=data['Close'],\n",
    "        mode='lines',\n",
    "        name='Stock Price',\n",
    "        line=dict(width=1)\n",
    "    ))\n",
    "\n",
    "    # Split signals by type and correctness\n",
    "    buy_signals = data[data['Predicted'] == 2]\n",
    "    sell_signals = data[data['Predicted'] == 1]\n",
    "    hold_signals = data[data['Predicted'] == 0]\n",
    "\n",
    "    # Correct/incorrect buy signals\n",
    "    correct_buy = buy_signals[buy_signals['Predicted'] == buy_signals['Actual']]\n",
    "    incorrect_buy = buy_signals[buy_signals['Predicted'] != buy_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect sell signals\n",
    "    correct_sell = sell_signals[sell_signals['Predicted'] == sell_signals['Actual']]\n",
    "    incorrect_sell = sell_signals[sell_signals['Predicted'] != sell_signals['Actual']]\n",
    "\n",
    "    # Correct/incorrect hold signals\n",
    "    correct_hold = hold_signals[hold_signals['Predicted'] == hold_signals['Actual']]\n",
    "    incorrect_hold = hold_signals[hold_signals['Predicted'] != hold_signals['Actual']]\n",
    "\n",
    "    # Plot buy signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_buy['Date'],\n",
    "        y=data.loc[correct_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=10, color='green')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_buy['Date'],\n",
    "        y=data.loc[incorrect_buy.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Buy Signal',\n",
    "        marker=dict(symbol='triangle-up', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot sell signals\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_sell['Date'],\n",
    "        y=data.loc[correct_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=10, color='red')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_sell['Date'],\n",
    "        y=data.loc[incorrect_sell.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Sell Signal',\n",
    "        marker=dict(symbol='triangle-down', size=8, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Plot hold signals (using a different symbol)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=correct_hold['Date'],\n",
    "        y=data.loc[correct_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Correct Hold Signal',\n",
    "        marker=dict(symbol='circle', size=8, color='blue')\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=incorrect_hold['Date'],\n",
    "        y=data.loc[incorrect_hold.index]['Close'],\n",
    "        mode='markers',\n",
    "        name='Incorrect Hold Signal',\n",
    "        marker=dict(symbol='circle', size=6, color='gray', opacity=0.2)\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'{ticker} Stock Price - Actual/Predicted Signals',\n",
    "        #xaxis_title='Date',\n",
    "        yaxis_title='Price (USD)',\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Call the modified function\n",
    "plot_combined_predictions(merged_df, 'PLTR')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "791757bc-255b-416a-8d6b-7fc72b79ba4f",
   "metadata": {},
   "source": [
    "from Components.BackTesting import BackTesting\n",
    "import pandas as pd\n",
    "\n",
    "#merged_df = pd.read_csv('Data/NASDAQ_100_PredictictionsData.csv')\n",
    "\n",
    "initial_capital = 10000.0\n",
    "ticker = 'PLTR'\n",
    "backtester = BackTesting(merged_df, ticker, initial_capital)\n",
    "results, _ = backtester.run_simulation()\n",
    "trades_fig, value_fig, exposure_fig = backtester.plot_performance()\n",
    "trades_fig.show()\n",
    "value_fig.show()\n",
    "exposure_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34fc912d83ccedf8",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7871d1ece2811692",
   "metadata": {},
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, dilation, padding, dropout=0.2):\n",
    "        super(TCNBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm1 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=output_dim,\n",
    "            out_channels=output_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm2 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu2 = nn.ReLU()  # Added missing relu2 activation\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Residual connection if dimensions don't match\n",
    "        self.residual = nn.Conv1d(input_dim, output_dim, 1) if input_dim != output_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First conv block\n",
    "        # Residual input\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        # Second conv block\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.relu2(out)  # Correctly use relu2\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        # Return to original shape\n",
    "        # Add the residual and pass through final activation\n",
    "        return self.relu1(out + residual)  # Fixed to use relu1 for the final activation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e373858219796207",
   "metadata": {},
   "source": [
    "class EchoStateNetwork(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, spectral_radius=0.9,\n",
    "                 sparsity=0.1, noise=0.001, bidirectional=False):\n",
    "        super(EchoStateNetwork, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.noise = noise\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Input weights (fixed)\n",
    "        self.register_buffer('W_in', self._initialize_input_weights())\n",
    "\n",
    "        # Reservoir weights (fixed)\n",
    "        self.register_buffer('W', self._initialize_reservoir_weights())\n",
    "\n",
    "        # Output weights (trainable)\n",
    "        self.W_out = nn.Linear(reservoir_size, output_size)\n",
    "\n",
    "        if bidirectional:\n",
    "            # Second set of weights for backward direction\n",
    "            self.register_buffer('W_in_reverse', self._initialize_input_weights())\n",
    "            self.register_buffer('W_reverse', self._initialize_reservoir_weights())\n",
    "            self.W_out_reverse = nn.Linear(reservoir_size, output_size)\n",
    "            # Combined output\n",
    "            self.W_combined = nn.Linear(output_size * 2, output_size)\n",
    "\n",
    "    def _initialize_input_weights(self):\n",
    "        W_in = torch.zeros(self.reservoir_size, self.input_size)\n",
    "        W_in = torch.nn.init.xavier_uniform_(W_in)\n",
    "        return W_in\n",
    "\n",
    "    def _initialize_reservoir_weights(self):\n",
    "        # Create sparse matrix\n",
    "        W = torch.zeros(self.reservoir_size, self.reservoir_size)\n",
    "        num_connections = int(self.sparsity * self.reservoir_size * self.reservoir_size)\n",
    "        indices = torch.randperm(self.reservoir_size * self.reservoir_size)[:num_connections]\n",
    "        rows = indices // self.reservoir_size\n",
    "        cols = indices % self.reservoir_size\n",
    "        values = torch.randn(num_connections)\n",
    "        W[rows, cols] = values\n",
    "\n",
    "        # Scale to desired spectral radius\n",
    "        eigenvalues = torch.linalg.eigvals(W)\n",
    "        max_eigenvalue = torch.max(torch.abs(eigenvalues))\n",
    "        W = W * (self.spectral_radius / max_eigenvalue)\n",
    "        return W\n",
    "\n",
    "    def _reservoir_step(self, x, h_prev, W_in, W):\n",
    "        \"\"\"Execute one step of the reservoir\"\"\"\n",
    "        # h_new = tanh(W_in @ x + W @ h_prev + noise)\n",
    "        h_new = torch.tanh(torch.mm(x, W_in.t()) + torch.mm(h_prev, W.t()) +\n",
    "                           self.noise * torch.randn(h_prev.shape, device=h_prev.device))\n",
    "        return h_new\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input tensor of shape (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Forward pass\n",
    "        h = torch.zeros(batch_size, self.reservoir_size, device=x.device)\n",
    "        outputs_forward = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h = self._reservoir_step(x[:, t], h, self.W_in, self.W)\n",
    "            outputs_forward.append(self.W_out(h))\n",
    "\n",
    "        outputs_forward = torch.stack(outputs_forward, dim=1)  # (batch_size, seq_len, output_size)\n",
    "\n",
    "        if not self.bidirectional:\n",
    "            return outputs_forward\n",
    "\n",
    "        # Backward pass for bidirectional ESN\n",
    "        h_reverse = torch.zeros(batch_size, self.reservoir_size, device=x.device)\n",
    "        outputs_reverse = []\n",
    "\n",
    "        for t in range(seq_len - 1, -1, -1):\n",
    "            h_reverse = self._reservoir_step(x[:, t], h_reverse, self.W_in_reverse, self.W_reverse)\n",
    "            outputs_reverse.insert(0, self.W_out_reverse(h_reverse))\n",
    "\n",
    "        outputs_reverse = torch.stack(outputs_reverse, dim=1)  # (batch_size, seq_len, output_size)\n",
    "\n",
    "        # Combine forward and backward outputs\n",
    "        combined = torch.cat((outputs_forward, outputs_reverse), dim=2)\n",
    "        return self.W_combined(combined)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8b0067a4686aadf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62964a9774211cfa",
   "metadata": {},
   "source": [
    "#ticker.get_balance_sheet(freq='quarterly')\n",
    "#ticker.get_calendar()\n",
    "#ticker.get_cash_flow(freq='quarterly')\n",
    "#earnings_data = ticker.get_earnings_dates()\n",
    "#income_statement = ticker.get_income_stmt(freq='yearly').T\n",
    "#ticker.get_institutional_holders()\n",
    "#ticker.get_recommendations()\n",
    "#ticker.get_sustainability()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "387ef9179077621f",
   "metadata": {},
   "source": [
    "# define a function to fetch the options data for a given ticker symbol\n",
    "#def fetch_options_data(ticker_symbol):\n",
    "    #ticker = yf.Ticker(ticker_symbol)\n",
    "#    options_dates = ticker.options\n",
    "#    options_data = ticker.option_chain(date='2025-03-21')\n",
    "#    return options_data.calls, options_data.puts\n",
    "##ionq_stock_data = ionq_stock_data.sort_values(by='Date', ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
